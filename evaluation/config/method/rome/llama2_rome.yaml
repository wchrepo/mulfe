model_name: meta-llama/Llama-2-7b-hf
preprocess: lmqg_ner
simplification: SimplificationWrapper
editor: 
  type: ROMEWrapper
  hparams: {
    "layers": [
        5
    ],
    "fact_token": "subject_last",
    "v_num_grad_steps": 25,
    "v_lr": 5e-4,
    "v_loss_layer": 31,
    "v_weight_decay": 5e-2,
    "clamp_norm_factor": 0.3,
    "kl_factor": 0.0625,
    "mom2_adjustment": true,
    "context_template_length_params": [[5, 10], [10, 10]],
    "rewrite_module_tmp": "model.layers.{}.mlp.down_proj",
    "layer_module_tmp": "model.layers.{}",
    "mlp_module_tmp": "model.layers.{}.mlp",
    "attn_module_tmp": "model.layers.{}.self_attn",
    "ln_f_module": "model.norm",
    "lm_head_module": "lm_head",
    "mom2_dataset": "wikipedia",
    "mom2_n_samples": 100000,
    "mom2_dtype": "float32"
  }