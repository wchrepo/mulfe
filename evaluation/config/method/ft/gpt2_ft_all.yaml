model_name: gpt2-xl
editor:
  type: FineTuning
  trainable_pattern: '.'
  opt_name: AdamW
  opt_kwargs:
    lr: 1e-4
    weight_decay: 0.0
  minibatch_tokens: 1024
  steps: 25
  early_stop: 0.005
  train_mode: False