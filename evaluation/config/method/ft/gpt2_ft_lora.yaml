model_name: gpt2-xl
editor:
  type: LoRAFineTuning
  lora_kwargs:
    r: 16
    lora_alpha: 16
    lora_dropout: 0.0
  opt_name: AdamW
  opt_kwargs:
    lr: 1e-4
    weight_decay: 0.0
  minibatch_tokens: 1024
  steps: 25
  early_stop: 0.005
  train_mode: True

  